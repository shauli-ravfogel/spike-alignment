{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import bert\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import spike_queries\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(fname):\n",
    "    \n",
    "    with open(fname, \"r\", encoding = \"utf-8\") as f:\n",
    "        sents = f.readlines()\n",
    "    \n",
    "    sents = [s.strip().split(\"\\t\")[-1] for s in sents]\n",
    "    original, results = sents[0], sents[1:]\n",
    "    return original, results\n",
    "\n",
    "\n",
    "def get_spike_results_arguments_representations(model, spike_results, layers):\n",
    "    \n",
    "    sents = spike_results[\"sentence_text\"].tolist()\n",
    "    arg1_idx_start = spike_results[\"arg1_first_index\"].to_numpy().astype(int)\n",
    "    arg2_idx_start = spike_results[\"arg2_first_index\"].to_numpy().astype(int)\n",
    "    arg1_idx_end = spike_results[\"arg1_last_index\"].to_numpy().astype(int)\n",
    "    arg2_idx_end = spike_results[\"arg2_last_index\"].to_numpy().astype(int)\n",
    "    \n",
    "    arg1_rep = []\n",
    "    arg2_rep = []\n",
    "    \n",
    "    for s, arg1_start, arg2_start, arg1_end, arg2_end in zip(sents, arg1_idx_start, arg2_idx_start, arg1_idx_end, arg2_idx_end):\n",
    "        #idx_to_mask = [arg1_start, arg2_start, arg1_end, arg2_end]\n",
    "        H, _, _, orig2tok = model.encode(s, layers = layers)\n",
    "\n",
    "        h1, h2 = H[orig2tok[arg1_start]:orig2tok[arg1_end] + 1], H[orig2tok[arg2_start]:orig2tok[arg2_end] + 1]\n",
    "        \n",
    "        h1 = np.mean(h1, axis = 0)\n",
    "        h2 = np.mean(h2, axis = 0)\n",
    "        \n",
    "        arg1_rep.append(h1)\n",
    "        arg2_rep.append(h2)\n",
    "        \n",
    "    arg1_mean = np.mean(arg1_rep, axis = 0)\n",
    "    arg2_mean = np.mean(arg2_rep, axis = 0)\n",
    "        \n",
    "    return arg1_mean, arg2_mean\n",
    "    \n",
    "\n",
    "def print_sentence_nicely(sentence: str, ind1, ind2):\n",
    "    \n",
    "    arg1_sign = \"**\"\n",
    "    arg2_sign = \"++\"\n",
    "    arg1_color, arg2_color = \"red\", \"blue\"\n",
    "    \n",
    "    if not ind2 > ind1: \n",
    "        ind1, ind2 = ind2, ind1\n",
    "        arg1_sign, arg2_sign = arg2_sign, arg1_sign\n",
    "        arg1_color, arg2_color = arg2_color, arg1_color\n",
    "        \n",
    "    splitted = sentence.split(\" \")\n",
    "    before_arg1 = \" \".join(splitted[:ind1])\n",
    "    arg1 = splitted[ind1]\n",
    "    arg2 = splitted[ind2]\n",
    "    between = \" \".join(splitted[ind1 + 1: ind2])\n",
    "    suffix = \" \".join(splitted[ind2+1:])\n",
    "    \n",
    "    return before_arg1 +  \" \" + arg1_sign + colored(arg1, arg1_color) + arg1_sign + \" \" + between + \" \" + arg2_sign + colored(arg2, arg2_color) + arg2_sign + \" \" + suffix\n",
    "\n",
    "\n",
    "\n",
    "def main(filename, layers = [-1], num_results_to_print = 6):\n",
    "    \n",
    "    \n",
    "    query, results1 = load_results(filename)\n",
    "    spike_results = spike_queries.perform_query(query, dataset_name = \"covid19\", num_results = 100, query_type = \"syntactic\")\n",
    "    spike_results = spike_results[spike_results['sentence_text'].notnull()]\n",
    "    arg1_rep, arg2_rep = get_spike_results_arguments_representations(model, spike_results, layers)\n",
    "    \n",
    "    #print(color.BOLD + \"QUERY\" + color.END + \":\\n{}\".format(query))\n",
    "    \n",
    "    first, first_ind1, first_ind2 = spike_results[\"sentence_text\"].tolist()[-1], int(spike_results[\"arg1_first_index\"].tolist()[-1]), int(spike_results[\"arg2_first_index\"].tolist()[-1])\n",
    "    #print(color.BOLD + \"\\nFIRST SPIKE RESULT\" + color.END + \":\\n{}\".format(print_sentence_nicely(first, first_ind1, first_ind2)))\n",
    "    #print(color.BOLD + \"\\nAUGMENTATION RESULTS:\\n\" + color.END)\n",
    "    \n",
    "    representations = []\n",
    "    mappings_to_orig = []\n",
    "    mappings_to_tok = []\n",
    "    tokenized_txts = []\n",
    "    orig_sents = []\n",
    "    \n",
    "    for i,s in enumerate(results1):\n",
    "        H, tokenized_text, tok_to_orig_map, orig2tok = model.encode(s, layers = layers)\n",
    "        orig_sents.append(s)\n",
    "        representations.append(H)\n",
    "        mappings_to_orig.append(tok_to_orig_map)\n",
    "        mappings_to_tok.append(orig2tok) \n",
    "        tokenized_txts.append(tokenized_text)\n",
    "        \n",
    "        if i > num_results_to_print: break\n",
    "    \n",
    "    return (arg1_rep, arg2_rep), (representations, mappings_to_orig, mappings_to_tok, tokenized_txts, orig_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at /home/shauli/.cache/torch/transformers/199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at /home/shauli/.cache/torch/transformers/199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/vocab.txt from cache at /home/shauli/.cache/torch/transformers/e3debd8fbdf40874753724814ee0520f612b577b26c8755bca485103b47cd3bc.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/added_tokens.json from cache at None\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/special_tokens_map.json from cache at None\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer_config.json from cache at None\n",
      "loading weights file https://cdn.huggingface.co/allenai/scibert_scivocab_uncased/pytorch_model.bin from cache at /home/shauli/.cache/torch/transformers/54e18c298451d3195ba8359e7a3fa2bc04c70c730c5b6744928278e67940eacb.7587182ea55c40bf7fd0961c1176c31fa22558da2bf20c199874fa5a8ecb4613\n"
     ]
    }
   ],
   "source": [
    "model = bert.BertEncoder(\"cuda\", \"scibert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_between_tokens_similarity(padded_representations):\n",
    "    \n",
    "    num_sents, seq_len, bert_dim = padded_representations.shape\n",
    "    padded_representations = padded_representations.reshape((num_sents*seq_len, bert_dim))\n",
    "    sims = cosine_similarity(padded_representations, padded_representations)\n",
    "    #sims = sims.reshape((num_sents, seq_len, num_sents, seq_len))\n",
    "    \n",
    "    return sims\n",
    "\n",
    "def get_similarity_to_arguments(padded_representations, arg1, arg2):\n",
    "    num_sents, seq_len, bert_dim = padded_representations.shape\n",
    "    padded_representations = padded_representations.reshape((num_sents*seq_len, bert_dim))    \n",
    "    sims = cosine_similarity([arg1_rep, arg2_rep], padded_representations)\n",
    "    sims = sims.reshape((2, num_sents, seq_len))\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "(arg1_rep, arg2_rep), (representations, mappings_to_orig, mappings_to_tok, tokenized_txts, orig_sents)  = main(\"results2.txt\", layers = [-1])\n",
    "for i in range(len(representations)): # zero cls, ., sep\n",
    "    representations[i][0][:] = 0.0\n",
    "    representations[i][-1][:] = 0.0\n",
    "    representations[i][-2][:] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(num_sents):\\n        sims_args[0][i][0] = 0.0\\n        sims_args[1][i][0] = 0.0\\n        sims_args[0][i][-1] = 0.0\\n        sims_args[1][i][-1] = 0.0\\n        sims_args[0][i][-2] = 0.0\\n        sims_args[1][i][-2] = 0.0\\n'"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_width = max([len(s) for s in representations])\n",
    "padded_representations = np.array([np.concatenate([r, np.zeros((pad_width-len(r), 768))]) for r in representations])\n",
    "num_sents, seq_len, bert_dim = padded_representations.shape\n",
    "num_tokens = num_sents * seq_len\n",
    "sims_token = get_between_tokens_similarity(padded_representations)\n",
    "sims_args = get_similarity_to_arguments(padded_representations, arg1_rep, arg2_rep)\n",
    "\"\"\"\n",
    "for i in range(num_sents):\n",
    "        sims_args[0][i][0] = 0.0\n",
    "        sims_args[1][i][0] = 0.0\n",
    "        sims_args[0][i][-1] = 0.0\n",
    "        sims_args[1][i][-1] = 0.0\n",
    "        sims_args[0][i][-2] = 0.0\n",
    "        sims_args[1][i][-2] = 0.0\n",
    "\"\"\"         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 416)"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import tqdm\n",
    "\n",
    "num_variables = sims_args.shape[1]\n",
    "#x = [[cp.Variable(1, boolean=True) for j in range(seq_len)] for i in range(num_sents)]\n",
    "X = cp.Variable((num_sents, seq_len), boolean = True)\n",
    "#Q = defaultdict(dict)\n",
    "\n",
    "#for i in range(num_sents):\n",
    "#    for j in range(seq_len):\n",
    "#        Q[i][j] = cp.Variable((num_sents, seq_len), boolean = True)\n",
    "Q = cp.Variable(sims_token.shape)\n",
    "\n",
    "similarity_to_arguments_component = cp.sum( cp.multiply(X, sims_args[0]))/(X.shape[0]*X.shape[1])\n",
    "similarity_between_tokens_component = cp.sum(cp.multiply(Q, sims_token))/(sims_token.shape[0]*sims_token.shape[1])\n",
    "#similarity_between_tokens_component = [ [[ [Q[i][j][k][l]*sims_token[i][j][k][l] for j in range(seq_len)] for  i \n",
    "#                                              in range(num_sents)] for l in range(seq_len)] for k in tqdm.tqdm(range(num_sents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = cp.Maximize(similarity_to_arguments_component + 0.25*similarity_between_tokens_component)\n",
    "#objective = cp.Maximize(cp.sum(X * sims_args[0]))\n",
    "constraints = []\n",
    "\n",
    "for i in range(num_sents):\n",
    "    constraints.append(cp.sum(X[i]) <= 1)\n",
    "    constraints.append(cp.sum(X[i]) >= 1)\n",
    "    \n",
    "    \n",
    "for i in tqdm.tqdm_notebook(range(sims_token.shape[0])):\n",
    "    y = i % seq_len # row ind\n",
    "    x = i // seq_len  # col ind\n",
    "    \n",
    "    for j in range(sims_token.shape[0]):\n",
    "        w = j % seq_len # second row ind\n",
    "        z = j // seq_len  # second col ind\n",
    "        constraints.append(cp.sum([-X[x][y]-X[z][w]+Q[i][j]]) >= -1)\n",
    "        constraints.append(cp.sum([X[x][y]-Q[i][j]]) >= 0)\n",
    "        constraints.append(cp.sum([X[z][w]-Q[i][j]]) >= 0)\n",
    "\n",
    "prob = cp.Problem(objective, constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-489-6815dd6e5c63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m         data, solving_chain, inverse_data = self.get_problem_data(\n\u001b[0;32m--> 744\u001b[0;31m             solver, gp, enforce_dpp)\n\u001b[0m\u001b[1;32m    745\u001b[0m         solution = solving_chain.solve_via_data(\n\u001b[1;32m    746\u001b[0m             self, data, warm_start, verbose, kwargs)\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36mget_problem_data\u001b[0;34m(self, solver, gp, enforce_dpp)\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0minverse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_data\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msolver_inverse_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolving_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m             safe_to_cache = (\n\u001b[1;32m    526\u001b[0m                 \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/reductions/chain.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0minverse_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/reductions/dcp2cone/dcp2cone.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccepts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot reduce problem to cone program\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDcp2Cone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/reductions/canonicalization.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# constraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             canon_constr, aux_constr = self.canonicalize_tree(\n\u001b[0;32m---> 68\u001b[0;31m                 constraint)\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mcanon_constraints\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maux_constr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcanon_constr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcons_id_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcanon_constr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/reductions/canonicalization.py\u001b[0m in \u001b[0;36mcanonicalize_tree\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;34m\"\"\"Recursively canonicalize an Expression.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# TODO don't copy affine expressions?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcvxtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             canon_expr, constrs = self.canonicalize_tree(\n\u001b[1;32m     90\u001b[0m               expr.args[0].objective.expr)\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/cvxpy/expressions/cvxtypes.py\u001b[0m in \u001b[0;36mpartial_problem\u001b[0;34m()\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpartial_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mcvxpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_optimize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPartialProblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPartialProblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "result = prob.solve(verbose=True)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(num_sents):\n",
    "    constraints.append(cp.sum(X[i]) <= 1)\n",
    "    constraints.append(cp.sum(X[i]) >= 1)\n",
    "    \n",
    "    for j in range(seq_len):\n",
    "        \n",
    "        for i2 in range(num_sents):\n",
    "            \n",
    "            for j2 in range(seq_len):\n",
    "                \n",
    "                q = cp.Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((260, 260), (5, 52))"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_token.shape, X.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971216"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27*52*27*52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After an incubation period of 5 to 14 days , SARS-CoV-2-infected people commonly manifest features of pneumonia , including fever , dry cough , dyspnoea , myalgia and fatigue .\n",
      "Argument: people\n",
      "---------------------------------------------\n",
      "After an incubation period of 2 to 3 days , patients who have pneumonic plague typically develop fulminant pneumonia , with malaise , high fever , cough , hemoptysis , and septicemia with ecchymoses and extremity necrosis .\n",
      "Argument: patients\n",
      "---------------------------------------------\n",
      "Patients suffering from severe DENV infection often exhibit encephalopathy and encephalitis .\n",
      "Argument: Patients\n",
      "---------------------------------------------\n",
      "Following an incubation period of usually 4 - 5 days , patients infected with SARS-CoV often present with symptoms of fever , headache , and myalgias .\n",
      "Argument: patients\n",
      "---------------------------------------------\n",
      "Cats with FIP show nonspecific clinical signs such as fever , weight loss and anorexia , often accompanied by body cavity effusions and/or ocular and neurological signs .\n",
      "Argument: Cats\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for x,orig_sent,tok2orig in zip(X,orig_sents,mappings_to_orig):\n",
    "    j = np.argmax(x.value)\n",
    "    if j in tok2orig:\n",
    "        print(orig_sent)\n",
    "        print(\"Argument: {}\".format(orig_sent.split(\" \")[tok2orig[j]]))\n",
    "    else:\n",
    "        print(\"none\")\n",
    "    \n",
    "    print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 52, 27, 52)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_token.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1971216"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27*52*27*52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "xval = X.value.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 52, 1, 52, 27, 52)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims_token[xval,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.ma.array(sims_token, mask=sims_token*xval[:,:,None,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 52, 27, 52)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 52, 1, 1)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xval[:,:,None,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
